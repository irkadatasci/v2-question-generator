# LLM Provider API Keys
# Configura al menos uno de estos 5 proveedores

# 1. Kimi (Moonshot AI) - Recomendado para documentos largos (128k contexto)
# Obtén la clave en: https://platform.moonshot.cn/
MOONSHOT_API_KEY=your_moonshot_api_key_here

# 2. Groq - Recomendado para procesamiento rápido (inferencia ultra-rápida)
# Obtén la clave en: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# 3. OpenAI - Recomendado para máxima calidad (GPT-4o)
# Obtén la clave en: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# 4. Ollama - Para uso local (gratis, requiere servidor Ollama en local)
# Documetación: https://ollama.com/
# Descarga modelos: ollama pull llama3.2
OLLAMA_HOST=http://localhost:11434

# 5. Ollama Cloud - Acceso a modelos cloud sin infraestructura local
# Obtén la clave en: https://ollama.com/
# Incluye modelos premium: DeepSeek, Ministral, GLM-4, etc.
OLLAMA_CLOUD_API_KEY=your_ollama_cloud_api_key_here
